<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Whisker-based Tactile Sensing and Shape Classification | Dong Ho Kang </title> <meta name="author" content="Dong Ho Kang"> <meta name="description" content="active vibrissal sensing to classify concave and convex objects using ANN and invtestigation in the transformation from the whisker base frame to the head frame using RL"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?968244106ed7c833589321ca0f99f9b2"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dokkev.github.io/projects/whisker-tactile/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Whisker-based Tactile Sensing and Shape Classification",
            "description": "active vibrissal sensing to classify concave and convex objects using ANN and invtestigation in the transformation from the whisker base frame to the head frame using RL",
            "published": "December 09, 2021",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Dong Ho</span> Kang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Whisker-based Tactile Sensing and Shape Classification</h1> <p>active vibrissal sensing to classify concave and convex objects using ANN and invtestigation in the transformation from the whisker base frame to the head frame using RL</p> </d-title> <d-article> <h2 id="overview">Overview</h2> <p>The objective of this project aims to replicate a rat’s active vibrissal sensing to classify concave and convex objects using artificial neural networks in simulations. Moreover, we investigated how individual whiskers affect neurons in the neural networks of the deep-q learning algorithm, which enabled the rat in simulation to find an optimal whisking orientation that maximizes the symmetry of contacting whiskers.</p> <ul> <li>The logistic regression model of 4 whiskers was able to classify concave and convex shapes with <strong>contact numbers</strong> with 0.81 accuracy.</li> <li>The neural network model of 4 whiskers was able to classify concave and convex shapes with <strong>peak moment</strong> with 0.92 accuracy.</li> <li>Inaccessibility to modify whisking amplitude in WHISKiT Physics simulator limited replicating Chris Rodger’s experiments.</li> <li>The neural network model of 54 whiskers was able to classify concave and convex shapes with <strong>contact duration</strong> with 0.92 accuracy while the rat was actively rotating its yaw.</li> <li>Image classification performed better than tabular data classification due to convolutional neural network that can process temporal and spatial data sufficiently</li> <li>Image classifier training was more time consuming than tabular data classifier DQN algorithm was implemented to investigate how individual whiskers affect the neural network which outputs a rat’s action to maximize symmetrical whiskers contact</li> </ul> <p><strong>Code: [<a href="https://github.com/dokkev/Whisker-Based-Tactile-Sensing-and-Shape-Classification" rel="external nofollow noopener" target="_blank">GitHub</a>]</strong></p> <h2 id="introduction">Introduction</h2> <p>Inspired by the ability of animals to maneuver effectively in their environment, biomimetic robotics has led to the diverse shapes and sizes of robot design. Biomimetic robot designs attempt to translate biological principles into engineered systems, replacing more classical engineering solutions to achieve a function observed in the natural system <sup>1</sup>.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/rat-480.webp 480w,/assets/img/whisker/rat-800.webp 800w,/assets/img/whisker/rat-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/rat.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1: A rat exploring a tunnel </div> <p>In this project, we are particularly interested in a rat’s ability to navigate intricate underground tunnels systems to the surface for scavenging in complete darkness. The rat’s exploratory behavior is dominated by intense “whisking,” rhythmic sweeps of the vibrissae (whiskers) that provide a continuous flow of tactile information to the rat’s brain. As they navigate, their whiskers make unexpected contact with an object, and the rat then explores the object to extract the details of its shape. The use of whisker inputs to detect, localize and extract the spatial properties of objects. These unique features allow rats to operate in complete darkness <sup>2</sup>.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/whiskit-480.webp 480w,/assets/img/whisker/whiskit-800.webp 800w,/assets/img/whisker/whiskit-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/whiskit.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="whiskit" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/whiskermap-480.webp 480w,/assets/img/whisker/whiskermap-800.webp 800w,/assets/img/whisker/whiskermap-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/whiskermap.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="whiskermap" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2: WHISKiT Physics Simulator (left) Figure 3: Whisker Mechanics and Matrix<sup>3</sup> (right) </div> <p>Studying real rats as a model is time-consuming and complex. Primarily, researchers have been unable to quantify the mechanosensory input at the base of each whisker. However, <a href="https://nadinazweifel.com/" rel="external nofollow noopener" target="_blank">Nadina Zweifel</a> has implemented <a href="https://github.com/SeNSE-lab/whiskitphysics" rel="external nofollow noopener" target="_blank">WHISKiT Physics Simulator</a>, and it allows us to investigate three-dimensional dynamic information of individual whisker.</p> <p>When a whisker makes contact with a 3D polygon mesh object in the simulation, the simulator calculates three-dimensional forces and moments at the whisker’s base using the <a href="https://github.com/bulletphysics/bullet3" rel="external nofollow noopener" target="_blank">Bullet Physics library</a>. Whiskers on a rat’s face exist in the form of matrices with their inherent names and functionality. This project will primarily investigate the transformation from the whisker base frame to the head frame using neural networcoordinateks to replicate a rat’s behavior during active whisking.</p> <h2 id="objectives">Objectives</h2> <p>While the contents of this project are wildly divergent, we have main objectives, which are the following two.</p> <h4 id="concave-and-convex-shape-classification-model">Concave and Convex Shape Classification Model</h4> <ul> <li>We have a lot of information coming from multiple whiskers. By varying the training input and neural network structure, we can explore the minimal requirement to perform successful concave-convex classification tasks.</li> <li>Implementation of real-time classification verifies the quality of the classification model. We can change the diameters of objects or the orientation of the rat to observe how those changes affect the classification result.</li> </ul> <h4 id="reinforcement-learning-and-the-coordinate-transformation">Reinforcement Learning and the Coordinate Transformation</h4> <ul> <li>A rat tends to bring its snout to the object as close as possible while ensuring whiskers contact the object symmetrically. We can use deep-q learning algorithms to replicate this behavior in the simulation.</li> <li>After sufficient training, we can evaluate the weights of each whisker to neurons in the input layer. We can investigate how an individual whisker affects the neural network to output the rat’s action during active sensing in the simulation (coordinate transformation from whisker frame to the head frame).</li> </ul> <h2 id="results">Results</h2> <h3 id="comparison-to-rodgers-experiment-classification-with-contact-number">Comparison to Rodger’s Experiment: Classification with Contact Number</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/rodgers-480.webp 480w,/assets/img/whisker/rodgers-800.webp 800w,/assets/img/whisker/rodgers-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/rodgers.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="rodgers" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/concave-480.webp 480w,/assets/img/whisker/concave-800.webp 800w,/assets/img/whisker/concave-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/concave.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="concave" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> *Figure 4: Rodger’s Experiment (left)* *Figure 5: 3D Modeling of Concave/Convex Object (right)* </div> <p>In his research, Chris Rodgers suggests that mice compared the number of contacts across whiskers to discriminate concave and convex shapes [4]. We replicated his experiment in simulations. Since Rodgers did not provide exact parameters for the experiment apparatus, such as radius of objects and distance between the mice and objects, we estimated those parameters from figures and videos. We created 3D modeling of a concave object with a 40 mm inner radius and a 42 outer radius with 25 mm height using Onshape.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/table1-480.webp 480w,/assets/img/whisker/table1-800.webp 800w,/assets/img/whisker/table1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/table1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table1" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/table2-480.webp 480w,/assets/img/whisker/table2-800.webp 800w,/assets/img/whisker/table2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/table2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table2" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>The simulation involved 3 different positions for both concave and convex objects adjusted with small variations of noise. For each orientation of the object, one cycle of whisking with C0, C1, C2, and C3 right whiskers was simulated 1,000 times to obtain a total of 6,000 samples of contact data. Table 2 below shows some samples of binary contact data. If a whisker made contact with an object anytime during the trial (one cycle of whisking), it received 1 to indicate contact. Figure 6 below shows the general trend of the data. Concave objects experienced a longer duration of contact compared to the convex objects overall, and C0 showed a significant difference between the concave and convex objects.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/chart-480.webp 480w,/assets/img/whisker/chart-800.webp 800w,/assets/img/whisker/chart-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/chart.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table1" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 6: Average Duration of Contact </div> <p>A binary classifier was implemented using logistic regression to discriminate concave and convex objects with contact numbers, and its accuracy was 0.81. However, Rodgers mentions he did not include C0 data in his analysis since the C0 whisker rarely touched the object during his experiments. Training and testing without C0 data, my logistic regression classifier could not perform its task with an accuracy rate below 0.5.</p> <h3 id="four-whiskers-task-classification-with-moment">Four Whiskers Task: Classification with Moment</h3> <p>Taking advantage of other types of data we obtained from the simulation, we expanded our classifier to train moment data. We calculated the magnitude of peak protraction moment excluding Mx for each trial, trained with logistic regression, and had the result of the accuracy of 0.84. Since moment data contained a more complex data type than binary contact data, we built a neural network-based classifier with Tensorflow and Keras. The classification accuracy improved to 0.92 using one hidden layer with four neurons.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/chart2-480.webp 480w,/assets/img/whisker/chart2-800.webp 800w,/assets/img/whisker/chart2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/chart2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="chart2" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 7: Average Peak Moment of Contact </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/fig8-480.webp 480w,/assets/img/whisker/fig8-800.webp 800w,/assets/img/whisker/fig8-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/fig8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="fig8" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 8: Peak Moment Classification with Neural Network </div> <p><a href="https://youtu.be/_m3zXwX3_xM" rel="external nofollow noopener" target="_blank"><img src="https://img.youtube.com/vi/_m3zXwX3_xM/0.jpg" alt="IMAGE_ALT"></a></p> <p><em>Video 1: Real-time Classification with Peak Moment</em></p> <p>While training input only contained simulation output with a fixed rat head orientation, we investigated how changing the pitch (looking up and down motion) affected classification accuracy. Video 1 shows the real-time classification with a pre-trained model (refer to Figure 7 for detailed information for the model). Gradually increasing the pitch, the classification failed around 26 degrees incrementation. The classification accuracy dropped significantly when the C0 whisker did not make contact. Since the model only takes inputs from four whiskers, each whisker takes a large proportion of classification accuracy. Hence, we proceeded with a different simulation setup to utilize all whiskers.</p> <h3 id="all-whiskers-simulation">All Whiskers Simulation</h3> <p>Utilizing more whiskers can increase the real-time classification performance while the rat is actively rotating and moving its head. Therefore, whisking over concave and convex objects was simulated using all 54 whiskers and 22 concave and convex objects with different radius. The inner radius of both concave and convex objects varied 20 mm to 40 mm by 2 mm increment. An object was placed at [X: 0 mm, Y: 30 mm, and Z: -10 mm, Yaw: 0.2 rad (concave) or 3.34 (convex), Pitch: 0 rad, Roll: 0 rad] configuration. The orientation of the rat head was varied by randomly adjusting the yaw of the rat head by +-90 degrees. Five cycles of whisking over each object were simulated 1,200 times, outputting 132,000 samples. Each sample contained data of force, moment, and contact of 54 whiskers during one cycle of whisking (125 ms in simulation time).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/fig9-480.webp 480w,/assets/img/whisker/fig9-800.webp 800w,/assets/img/whisker/fig9-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/fig9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="fig9" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 9: Yaw adjustment of the Rat Head </div> <h3 id="all-whiskers-classification-contact-duration">All Whiskers Classification: Contact Duration</h3> <p>One cycle of whisking takes 125 ms in the simulation time, and contact duration is determined by how long the whisker made contact with the object during one cycle of whisking. This data was used to build a classifier. It converged to 0.99 accuracies using one hidden layer with 36 neurons which is ⅔ of the input size. This model was verified with a real-time classification which allowed the rat head’s forward motion and rotation in the yaw axis. Video 2 demonstrates the real-time classification of a moving rat head with a concave object. The classification failed when not a sufficient number of whiskers were making contact with the objects. This result leads us to the next step of the project to ensure the rat’s optimal orientation while actively whisking.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/fig10-480.webp 480w,/assets/img/whisker/fig10-800.webp 800w,/assets/img/whisker/fig10-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/fig10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="fig10" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 10: Contact Duration Classification with Neural Network </div> <p><a href="https://youtu.be/QAoV4th5TsM" rel="external nofollow noopener" target="_blank"><img src="https://img.youtube.com/vi/QAoV4th5TsM/0.jpg" alt="IMAGE_ALT"></a></p> <p><em>Video 2: All Whisker Real-time Classification</em></p> <h3 id="reinforcement-learning-and-coordinate-transformation">Reinforcement Learning and Coordinate Transformation</h3> <p>We have witnessed how the orientation of a rat’s head during active whisking affects classification performance. We implemented a model which enables symmetric contact of whiskers while maximizing the contact number using the Deep-Q learning algorithm.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/eq1-480.webp 480w,/assets/img/whisker/eq1-800.webp 800w,/assets/img/whisker/eq1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/eq1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="eq1" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Equation 1: Q-algorithm </div> <p>During simulation, the q-function is updated upon every action the rat takes. The rat has five actions which are: [turn right, turn left, look up, look down, stay]. Gamma decides which rat should take its next action based on the q-function or completely random action. The rat takes random actions due to limited information in the q-function. As the training progresses, the gamma value is adjusted to encourage the rat to take action based on q-function. Alpha is a learning rate that affects how much the neural network will embrace the new value replacing the existing value. The learning rate in the training depends on the protraction status of the whiskers. The learning rate is proportional to the angle of whiskers to weight information received during peak protraction.</p> <p><a href="https://youtu.be/5qes33DmmsY" rel="external nofollow noopener" target="_blank"><img src="https://img.youtube.com/vi/5qes33DmmsY/0.jpg" alt="IMAGE_ALT"></a></p> <p><em>Video 3: Early State Training</em></p> <p>The symmetrical contact of whiskers and contact number decide the reward value. Contact symmetry is weighted more heavily than a contact number to replicate a real rat’s behavior. When the sum of rewards of one cycle of whisking does not reach the given threshold, the rat head orientation is set to the default position and receives a negative reward.</p> <h2 id="discussion">Discussion</h2> <h3 id="whisking-amplitude-adjustment-is-necessary-to-replicate-a-real-rat">Whisking Amplitude Adjustment is Necessary To Replicate a Real Rat</h3> <p>Rodgers states that he excluded the C0 whisker from his analysis since “it rarely made contact with the object”. However, my simulation result suggests that the C0 whisker contains significant information to distinguish between concave and convex shapes as seen in Figure 6. Neither contact number nor peak moment model performed classification task without training the C0 data. While a real rat can adjust the whisking amplitude, the simulator follows a given time-specified whisking trajectory. Therefore, we concluded that it was not feasible to fully replicate Rodger’s experiment due to the limits of the WHISKiT Physics Simulator.</p> <h3 id="temporal-dependent-input-data-allows-successful-classification">Temporal dependent Input Data Allows Successful Classification</h3> <p>The rat successfully classified concave and convex objects with 54 whiskers while actively adjusting its orientation. This model was trained with one hidden layer with 36 neurons. The number of neurons was decided by factoring ⅔ to the input size. Adjusting the number of neurons in the hidden layer changed convergence time, but it did not significantly affect the classification accuracy.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/fig11-480.webp 480w,/assets/img/whisker/fig11-800.webp 800w,/assets/img/whisker/fig11-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/fig11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="fig11" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 11: Contact Duration (left) vs Contact Number (right) </div> <p>Besides contact duration classifiers, other types of classifiers use more high-level dynamic data input such as the averages of moments, derivatives of moments, averages of forces, and derivatives of forces of each whisker. They all successfully converged to 0.99 accuracies and outperformed in real-time classification. On the other hand, the contact number and peak moment classifier lacked the capabilities to process simulation output from various yaw angles of the rat head since they underperformed with around 0.85 accuracies. We concluded that data such as contact duration involves time-dependent information, and it allows successful classification with non-fixed head orientation.</p> <h3 id="contact-data-conversion-to-gray-image">Contact Data Conversion to Gray Image</h3> <p>Data from whiskers have temporal and spatial dependencies. However, the WHISKiT Physics Simulator saves its results as tabular data. In his paper, Zhu states that most tabular data do not assume a spatial and temporal relationship between features. Convolutional Neural Networks (CNN) are inspired by visual neuroscience and possess key features that exploit the properties of natural signals, including local connections in receptive fields, parameter sharing via convolution kernel, and hierarchical feature abstraction through pooling and multiple layers. These features make CNNs suitable for analyzing data with spatial or temporal dependencies between components <sup>4</sup>.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/fig12-480.webp 480w,/assets/img/whisker/fig12-800.webp 800w,/assets/img/whisker/fig12-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/fig12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="fig12" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 12: Conversion of Binary Contact to Gray Image </div> <p>Hence we attempted to convert tabular data to images to train CNN based classifiers. While the image row represents each whisker, the column represents time series in simulation. Data is fed into a 2D array 0 as no-contact and 255 as contact to make a gray-scale image, and we are able to visualize when and where the whiskers made contact with objects during the simulation.</p> <h3 id="moment-data-conversion-to-rgb-image">Moment Data Conversion to RGB Image</h3> <p>The same concept can be applied to three-dimensional force data. Inserting Mx data into a red layer, My into a green layer, and Mz into a blue layer, we can represent each moment data with whisker type and time as separate dimensions.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/fig13-480.webp 480w,/assets/img/whisker/fig13-800.webp 800w,/assets/img/whisker/fig13-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/fig13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="fig13" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 13: Conversion of 3D Moment to RGB Image </div> <p>Since data is normalized for images, it is not feasible to produce a real-time RGB image unless color values are pre-defined as ranges. However, these RGB images allow us to interpret the data easily with an RGB combination diagram. Figure 14 shows the average three-dimensional moment during five cycles of whisking. Training image classifiers was more time-consuming than tabular data classifiers. Since concave and convex simulation was simple enough to use contact duration tabular classifiers and had 0.99 accuracy, training image classifiers were not further investigated.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/whisker/fig14-480.webp 480w,/assets/img/whisker/fig14-800.webp 800w,/assets/img/whisker/fig14-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/whisker/fig14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="fig14" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 14: 3D Average Moment in RGB Image </div> <h2 id="conclusion">Conclusion</h2> <p>In this project, we investigated neural networks for concave and convex shape classification. This task was achieved using tabular data training, but future works that require more complicated multi-class classification will require image classification. We will plan to modify WHISKiT Physics Simulator to compare to Rodger’s experiment. It was especially challenging to implement temporal dependencies in the DQN algorithm. Since previous actions taken by the rat affects the present reward, we had to keep track of real-time reward that captures real-time contact data and long-time reward which evaluates the whisking performance of each cycle. Moreover, it was crucial that the simulator does not have multi-threading functions. Training DQN was time-consuming due to the slow physics calculations of each whisker.</p> <h1 id="citation">CITATION</h1> <p>[1] Cho KJ., Wood R. (2016) Biomimetic Robots. In: Siciliano B., Khatib O. (eds) Springer Handbook of Robotics. Springer Handbooks. Springer, Cham. https://doi.org/10.1007/978-3-319-32552-1_23</p> <p>[2] Hartmann MJ. A night in the life of a rat: vibrissal mechanics and tactile exploration. Ann N Y Acad Sci. 2011 Apr;1225:110-8. doi: 10.1111/j.1749-6632.2011.06007.x. PMID: 21534998.</p> <p>[3] Zweifel, Nadina &amp; Bush, Nick &amp; Abraham, Ian &amp; Murphey, Todd &amp; Hartmann, Mitra. (2019). WHISKiT Physics: A three-dimensional mechanical model of the rat vibrissal array. 10.1101/862839.</p> <p>[4] Zhu, Y., Brettin, T., Xia, F. et al. Converting tabular data into images for deep learning with convolutional neural networks. Sci Rep 11, 11325 (2021). https://doi.org/10.1038/s41598-021-90923-y</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Dong Ho Kang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: March 28, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"Robotics Portfolio",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-resources-for-learning-robotics",title:"Resources for Learning Robotics",description:"Collection of useful resources for learning robotics.",section:"Posts",handler:()=>{window.location.href="/Intro-to-Robotics/"}},{id:"post-robotic-hand-01-direct-driven-robotic-hand",title:"[Robotic Hand 01] - Direct Driven Robotic Hand",description:"Direct Driven Robotic Hand with ESP32, simpleFOC, and SocketCAN",section:"Posts",handler:()=>{window.location.href="/motorcan/"}},{id:"post-can-04-gripper-motor-control-with-can-bus",title:"[CAN 04] - Gripper Motor Control with CAN Bus",description:"Single Motor Control with ESP32, simpleFOC, and SocketCAN for Robotic Gripper",section:"Posts",handler:()=>{window.location.href="/motorcan/"}},{id:"post-can-03-communicating-to-esp32-with-socketcan",title:"[CAN 03] - Communicating to ESP32 with SocketCAN",description:"SocketCAN Communication with ESP32",section:"Posts",handler:()=>{window.location.href="/esp32can/"}},{id:"post-can-02-setting-up-socketcan-on-linux",title:"[CAN 02] - Setting up SocketCAN on Linux",description:"Setting up SocketCAN",section:"Posts",handler:()=>{window.location.href="/socketcan/"}},{id:"post-can-01-what-is-can",title:"[CAN 01] - What is CAN?",description:"What is CAN Bus and how is it used in robotics?",section:"Posts",handler:()=>{window.location.href="/aboutcan/"}},{id:"news-our-paper-rpc-a-modular-framework-for-robot-planning-control-and-deployment-has-been-accepted-to-the-2025-ieee-sice-international-symposium-on-system-integration-sii",title:"Our paper RPC: A Modular Framework for Robot Planning, Control, and Deployment has...",description:"",section:"News"},{id:"projects-cup-tower-stacking-with-baxter",title:"Cup Tower Stacking with Baxter",description:"Baxter stacks tower of cups with Moveit, Apriltag, and OpenCV",section:"Projects",handler:()=>{window.location.href="/projects/baxter-tower/"}},{id:"projects-bldc-motor-control-with-pid-controller",title:"BLDC Motor Control with PID Controller",description:"BLDC Motor Control with NU32 micrcontroller and DRV8835 H-bridge motor driver",section:"Projects",handler:()=>{window.location.href="/projects/motor/"}},{id:"projects-autonomous-fire-fighting-robot",title:"Autonomous Fire Fighting Robot",description:"Sensing and Localization of Fire, Grasping, and Operating Fire Extinguisher",section:"Projects",handler:()=>{window.location.href="/projects/firefigther/"}},{id:"projects-progamming-pic32-with-c",title:"Progamming PIC32 with C",description:"UART, SPI, LCD, LED, IMU, and more",section:"Projects",handler:()=>{window.location.href="/projects/PIC32/"}},{id:"projects-impact-modeling-with-euler-lagrangian-and-hamiltonian-mechanics",title:"Impact Modeling with Euler-Lagrangian and Hamiltonian Mechanics",description:"4 point mass system impact simulation in Python with SymPy",section:"Projects",handler:()=>{window.location.href="/projects/impact/"}},{id:"projects-whisker-based-tactile-sensing-and-shape-classification",title:"Whisker-based Tactile Sensing and Shape Classification",description:"active vibrissal sensing to classify concave and convex objects using ANN and invtestigation in the transformation from the whisker base frame to the head frame using RL",section:"Projects",handler:()=>{window.location.href="/projects/whisker-tactile/"}},{id:"projects-humanoid-robot-control-with-pypnc",title:"Humanoid Robot Control with PyPnC",description:"Whole Body Control and DCM Planner based Locomotion in PyBullet",section:"Projects",handler:()=>{window.location.href="/projects/pypnc/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%6F%6E%67%68%6F@%75%74%65%78%61%73.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=YlYSer0AAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/dokkev","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>