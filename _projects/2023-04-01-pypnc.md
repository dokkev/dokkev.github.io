---
layout: distill
title: Humanoid Robot Control with PyPnC
description: Whole Body Control and DCM Planner based Locomotion in PyBullet
img: assets/img/humanoid/humanoid.gif
importance: 9
category: robotics
related_publications: false
---

This project aims to simulate a humanoid robot's walking and balancing using Whole Body Control (WBC) and Divergent Component of Motion (DCM) planner using URDF models of Boston Dynamics' ATLAS in the PyBullet environment. This project was implemented from [PyPnC](https://github.com/junhyeokahn/PyPnC) as a part of The University of Texas at Austin's Design and Control of Human-Centered Robotics (ASE389) course.

# Humanoid Modeling under Multi-Contact Constraints
Challenges in humanoid robots involve high dimensionality, underactuation, and operation under geometrical and multi-contact constraints. A humanoid robot’s behavior is determined by not only the displacements of its articulated joints but also interactions of its bodies in contact.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/kinematic_model.png" title="model" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 1: Kinematic representation of a humanoid robot The free moving base is represented as a virtual spherical joint in series with three prismatic virtual joints. Reaction forces appear at the contact points due to gravity forces pushing the body against the ground. Contact constraints are expressed as rigid constraints with zero velocities and accelerations at the supporting bodies [1].*
</div>

The equation of motion (EOM) which is subjected to actuation torques and external forces can be derived using the Euler-Lagrange equation.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/eq1.png" title="eq1" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   Equation of Motion 1
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/eq2.png" title="eq2" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   Equation of Motion 2
</div>

where A is the (n + 6) × (n + 6) inertia matrix, b and g are (n + 6) × 1 vectors of Coriolis/centrifugal and gravity forces.
For more detail, refer to [Compliant Control of Whole-Body Multi-Contact Behaviors in Humanoid Robots](http://sites.utexas.edu/hcrl/files/2016/01/book-chapter-springer.pdf)

# Joint Space Control, Operational Space Control, and Whole Body Control

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/arm.png" title="arm" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 2: A 3-link planar robot arm*
</div>

EOM above can be developed into different control schemes, and they can be shown with a simple 3-link planar robot arm which is more intuitive than a complex humanoid robot to explore features of each control scheme.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/jpos.jpg" title="jpos" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 3: Joint Space Control with PD Controller*
</div>

Firstly, joint space control takes desired joint configuration as an input and outputs joint torques with feedback control.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/osc.jpg" title="osc" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 4: Operational Space Control with PD Controller*
</div>

Secondly, operational space control takes control the end-effector's motion in the task space by controlling the forces and torques in the control space. Operational space control is a more high-level and task-specific control as it enables the specification of desired end-effector behaviors in the task space, rather than specifying joint angles or velocities in the control space.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/wbc.jpg" title="wbc" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 5: Prioritized Whole Body Control (Task and Posture Control)*
</div>

Finally, prioritized whole body control can perform two tasks which conflict with each other. Figure 5 shows the desired joint configuration as [0,0,0] (task: x2) which configures the robot to stretch in a straight line while attempting to achieve the desired end-effector orientation as π/4 (task: x1) which is not feasible with the desired joint configuration at [0,0,0]. Prioritized whole body control law can set a higher priority of task x1 over task x2. In this case, the robot achieves the desired end-effector orientation while trying to minimize the error in the desired joint configuration. This control law ensures accomplishment of critical tasks over sub-tasks, and it enables whole-body compliant behaviors and exploits the redundancy of humanoids under geometric and contact constraints.

# Whole Body Control: Stand and Balance

WBC for humanoid balancing can be formulated with an optimization problem which minimizes the joint acceleration and reaction forces. It can be represented as:

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/opt.png" title="wbc_optimize" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Optimization Problem for WBC*
</div>

The optimization is subjected to the cost function, equality constraints, and inequality constraints, and boundaries of joint acceleration and command torques. The optimization problem is solved with a quadratic programming (QP) solver.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/qp1.png" title="qp1" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Quadratic Programming Step 1*
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/qp2.png" title="qp2" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Quadratic Programming Step 2*
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/qp3.png" title="qp3" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Quadratic Programming Step 3*
</div>

The cost function is a quadratic function of joint acceleration and reaction forces. The equality constraints are the EOM and the kinematic constraints which allow the robot to stand on the ground by the law of physics. The inequality constraints include the wrench term while the inequality vector is determined by the gravity and Coriolis term. The wrench term ensures that the direction of the normal force under gravity and Coriolis force prevent the foot from slipping and flipping. While Coulomb friction law defines the relationship between the frictional and normal force of two surfaces in contact, inequality constraints enforce a minimum normal force during the optimization. The inequality constraints also prevent saturation of the joint acceleration and command torques. 

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/balance.gif" title="balance" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 6: Humanoid balancing with WBC*
</div>

# DCM Planner: Trajectory Generation
While DCM is a quantity in Cartesian space that is related to the COM position and velocity, DCM Planner generates walking patterns using the virtual repellent point (VRP) which is a point in Cartesian space that encodes both direction and magnitude of the external forces acting on the robot. 

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/dcm.png" title="dcm" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 7: DCM and VRP: COM tends to converge to DCM while VRP repels DCM*
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/dcm1.png" title="dcm1" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *DCM Planner Step 1*
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/dcm2.png" title="dcm2" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *DCM Planner Step 2*
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/humanoid/dcm3.png" title="dcm3" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
   *Figure 8: Forward Walking Trajectory (Top) and Backward Walking Trajectory (Bottom)*
</div>

# Forward, Backward, and Sideway Walking

<figure>
  <iframe
    width="720"
    height="405"
    src="https://www.youtube.com/embed/Z7ltbP7t3zI"
    title="Humanoid Robot Walking Demonstration"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
  </iframe>
  <figcaption style="text-align: center;">
    <em>Forward, Backward, and Sideway Walking Demonstration</em>
  </figcaption>
</figure>